{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(precision=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    y = np.exp(x)\n",
    "    return y/np.sum(y)\n",
    "\n",
    "\n",
    "def ExpBernoulliAlt(alpha,lam,size=None,method='binomial',N=1000): # returns True with probability $e^{alpha-lam}$\n",
    "    if size is None: \n",
    "        size = (1,)\n",
    "    if type(size) is int:\n",
    "        size = (size,)\n",
    "    elif type(size) is not tuple:\n",
    "        raise TypeError(\"size must be int or tuple\")\n",
    "    \n",
    "    if method == 'poisson':\n",
    "        M=np.random.poisson(lam=lam,size=size) # Get integers from poisson(lam).\n",
    "    elif method == 'binomial': # N is number to flip\n",
    "        M=np.random.binomial(N,lam/N,size=size)\n",
    "\n",
    "    spikes = np.random.random(size)<np.power(alpha/lam,M) # Spike if all K trials are successful\n",
    "    return spikes\n",
    "\n",
    "def approx_fn(q,K,T,comb_method='OR'):\n",
    "    n_embed,n_keys = K.shape\n",
    "\n",
    "    # Create spike arrays based on the values in q and K\n",
    "    q_spikes = np.random.random((T,n_embed,1))<q\n",
    "    K_spikes = np.random.random((T,n_embed,n_keys))<K\n",
    "    scaling_spikes = np.random.random((T,n_embed,n_keys)) < 1/np.sqrt(n_embed) # K x N matrix of boolean mask\n",
    "    attn_score_spikes = q_spikes & K_spikes & scaling_spikes # AND\n",
    "\n",
    "    # Summing works better, but OR can work well if input rates are low\n",
    "    if comb_method == 'OR':\n",
    "        attn_score_spikes = np.any(attn_score_spikes, axis=1) # OR\n",
    "    elif comb_method == 'SUM':\n",
    "        attn_score_spikes = np.sum(attn_score_spikes, axis=1) # SUM\n",
    "    else:\n",
    "        assert(0)\n",
    "    # approx_attn_scores = np.mean(attn_score_spikes,axis=0) # Get spike rates\n",
    "    return attn_score_spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Computing the scaled dot product between two vectors\n",
    "\n",
    "Query: $q$\\\n",
    "Key: $k$\\\n",
    "Scaled dot product: $q\\cdot k/\\sqrt{N}$\n",
    "\n",
    "\n",
    "Basic method: \n",
    "\n",
    "* Create spikes trains with rates proportional to the elements of $k$, $q$ and $1/\\sqrt{N}$ (where $N$ is the lenght of $q,k$).\n",
    "* Use AND gates to combine this, yields spike trains with rates proportional to $q_ik_i/\\sqrt{N}$.\n",
    "* Sum these spike trains together. If each individual spike train is sufficiently sparse, we can approximate this with an inclusive OR.\n",
    "\n",
    "Challenges: \n",
    "* What if we want to using key or query vectors that are not in $[0,1]^N$?\n",
    "* What if input spike trains are not very sparse? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact scaled dot product:  0.01505\n",
      "Approximation using spikes:  0.01439\n",
      "Percent error:  4.37945 %\n",
      "Angle:  0.54254  radians\n"
     ]
    }
   ],
   "source": [
    "N=5 # Embedding dimension\n",
    "T=100000 # Number of trials / steps\n",
    "max_rate = 0.2 # Maximum allowed spike probability\n",
    "\n",
    "# Generate two random vectors in [0,1]^N\n",
    "q,k = max_rate*np.random.random((2,N,1)) # spike probabilties for key and query\n",
    "\n",
    "# Approximate scaled dot product using spikes\n",
    "approx = np.mean(approx_fn(q,k,T,comb_method='OR'),axis=0).item()\n",
    "\n",
    "# Exact scaled dot product\n",
    "exact = (q.T@k/np.sqrt(N)).item()\n",
    "\n",
    "# Error\n",
    "percent_error = np.abs((approx - exact) / exact) * 100\n",
    "angle = np.arccos(q.T@k/np.sqrt(q.T@q*k.T@k)).item()\n",
    "\n",
    "print(\"Exact scaled dot product: \", round(exact, 5))\n",
    "print(\"Approximation using spikes: \", round(approx, 5))\n",
    "print(\"Percent error: \", round(percent_error, 5), \"%\")\n",
    "print(\"Angle: \", round(angle, 5), \" radians\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is the effect of sparsity?\n",
    "\n",
    "* The OR method works better for sparse spike trains, because the probability of collisions is low.\n",
    "* The SUM method works better for dense spike trains, because the variance of the sample spike rate is lower.\n",
    "* Let's compare these!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* As can be seen above, higher spike probabilities lead to less accurate approximations when combining channels using the inclusive OR method. \n",
    "* How does the maximum spike probability of the inputs affect this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12900/1380819567.py:18: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  error = np.sqrt(np.mean(diff**2)/np.mean(attn_scores**2))*100\n",
      "/tmp/ipykernel_12900/1380819567.py:24: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  error = np.sqrt(np.mean(diff**2)/np.mean(attn_scores**2))*100\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_embed=64 # Embedding dimension\n",
    "n_keys=100 # Number keys\n",
    "T=50000 #50000 # Number of time steps\n",
    "\n",
    "OR_errors, SUM_errors = [], []\n",
    "max_rates = np.linspace(0.0,0.5,20)\n",
    "\n",
    "for max_rate in max_rates:\n",
    "\n",
    "    # Get keys/query and compute exact scaled dot products\n",
    "    q =  max_rate*np.random.random((n_embed,1)) # Query\n",
    "    K = max_rate*np.random.random((n_embed,n_keys)) # Keys\n",
    "    attn_scores = q.T@K/np.sqrt(n_embed) # Exact attention scores\n",
    "\n",
    "    # OR (avg error) \n",
    "    approx_attn_scores = np.mean(approx_fn(q,K,T,comb_method='OR'),axis=0)\n",
    "    diff = attn_scores - approx_attn_scores\n",
    "    error = np.sqrt(np.mean(diff**2)/np.mean(attn_scores**2))*100\n",
    "    OR_errors.append(error)\n",
    "\n",
    "    # SUM (avg error) \n",
    "    approx_attn_scores = np.mean(approx_fn(q,K,T,comb_method='SUM'),axis=0)\n",
    "    diff = attn_scores - approx_attn_scores\n",
    "    error = np.sqrt(np.mean(diff**2)/np.mean(attn_scores**2))*100\n",
    "    SUM_errors.append(error)\n",
    "\n",
    "plt.plot(max_rates,OR_errors,label='OR')\n",
    "plt.plot(max_rates,SUM_errors,label='SUM')\n",
    "plt.xlabel('Maximum allowed spike probability for key/query elements')\n",
    "plt.ylabel('Fractional error (%)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Softmax\n",
    "\n",
    "Given a vector $\\bar{\\alpha}=(\\alpha_1,\\alpha_2,\\ldots,\\alpha_n)$, we define: $softmax(\\bar{\\alpha})=(e^{\\alpha_i-\\lambda})_{i\\in n}$, where $\\lambda=LSE(\\bar{\\alpha})=log(\\sum e^{\\alpha_i})$\n",
    "\n",
    "* Rather than trying to compute $\\lambda$ explicitly, we note that $\\lambda$ is the unique value that makes the softmax entries sum to 1. \n",
    "* We can adjust $\\lambda$ dynamically to make this true. \n",
    "* Therefore, the problem of compute softmax reduces to the problem of computing exponentials (using spikes).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Idea\n",
    "\n",
    "* Use the approximation: $e^{\\alpha-\\lambda}\\approx (1-\\frac{\\lambda-\\alpha}{N})^N$ for large $N$.\n",
    "* This reduces the problem. We just need to be able to generate spikes with probability $1-(\\lambda-\\alpha)/N$.\n",
    "* It may be useful to rewrite this expression as a more complex probability: $1-(\\lambda-\\alpha)/N=1-(\\lambda/N)(1-\\alpha/\\lambda)$\n",
    "* This expression is the probability that $A\\to B$, where $A$ and $B$ are independent Bernoulli r.v.s with probabilities $\\lambda/N$ and $\\alpha/\\lambda$, respectively.\n",
    "* Details: Let A and B be (independent) Bernoulli r.v.s Then $P(A\\to B) = P(\\lnot(A\\wedge\\lnot B))=1-P(A)[1-P(B)]$\n",
    "* Method: Flip $N$ coins each with probability $\\lambda/N$. For each coin that comes up heads, flip a coin with probability $\\alpha/\\lambda$. If all of the coins on this second round come up heads, we transmit a spike. The probability of spiking will be roughly $e^{\\alpha-\\lambda}$ if $N$ is sufficiently large. \n",
    "\n",
    "\n",
    "<!-- ![Exponential spiking](image1.svg) -->\n",
    "\n",
    "<img src=\"image1.svg\" alt=\"Description\" width=\"50%\"/>\n",
    "\n",
    "Note: The number of successes on the first round is distributed roughly like Poisson($\\lambda$) when $N$ is large. What if we actually use Poisson($\\lambda$)?\n",
    "\n",
    "Suppose that $k\\sim Poisson(\\lambda)$. What is the probability that $k$ independent Bernoulli($\\frac{\\alpha}{\\lambda}$) trials are all successful?\n",
    "\n",
    "Spike probability: $\\sum_k p(k)(\\frac{\\alpha}{\\lambda})^k=\\sum_k e^{-\\lambda}\\frac{\\lambda^k}{k!}(\\frac{\\alpha}{\\lambda})^k=e^{-\\lambda}\\sum_k\\frac{\\alpha^k}{k!}=e^{\\alpha-\\lambda}$.\n",
    "\n",
    "<!-- What if we replace the Poisson with a Binomial approximation (using N trials and success probability $\\lambda/N$)?\n",
    "\n",
    "Answer: $\\sum_k {N\\choose k}(\\frac{\\lambda}{N})^k(1-\\frac{\\lambda}{N})^{N-k}(\\frac{\\alpha}{\\lambda})^k=(1-\\frac{\\lambda}{N})^N\\sum_k{N \\choose k}(\\frac{\\alpha}{N-\\lambda})^k$ -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact exponential:  0.3678794411714424\n",
      "Approximation using spikes:  0.36521\n",
      "Error:  0.725629342847233 %\n"
     ]
    }
   ],
   "source": [
    "# Basic exponential\n",
    "\n",
    "T=100000\n",
    "alpha = 5*np.random.random()\n",
    "lam = alpha + 1\n",
    "\n",
    "# Exact exponential\n",
    "exact = np.exp(alpha-lam)\n",
    "print(\"Exact exponential: \",exact)\n",
    "\n",
    "# Approximate exponential using spikes\n",
    "spikes = ExpBernoulliAlt(alpha,lam,T)\n",
    "approx = np.mean(spikes)\n",
    "print(\"Approximation using spikes: \",approx)\n",
    "\n",
    "# Error\n",
    "error = np.abs((exact-approx)/exact)\n",
    "print(\"Error: \",100*error,'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total probability (this should be 1):  5.6697299999999995\n",
      "Total probability (this should be 1):  0.54815\n",
      "Total probability (this should be 1):  0.6869000000000001\n",
      "Total probability (this should be 1):  0.80474\n",
      "Total probability (this should be 1):  0.88513\n",
      "Total probability (this should be 1):  0.93638\n",
      "Total probability (this should be 1):  0.96611\n",
      "Total probability (this should be 1):  0.98882\n",
      "Total probability (this should be 1):  0.9968899999999999\n",
      "Total probability (this should be 1):  0.9964900000000001\n",
      "\n",
      "\n",
      "Original vector:  [0.913 0.961 0.532 0.65  0.102 0.269 0.789 0.406]\n",
      "Exact softmax:  [0.168 0.176 0.115 0.129 0.075 0.088 0.148 0.101]\n",
      "Approximation using spike:  [0.167, 0.17514, 0.11452, 0.1285, 0.07442, 0.08873, 0.14753, 0.10065]\n",
      "Error:  0.5037065999649422 %\n"
     ]
    }
   ],
   "source": [
    "# Basic softmax\n",
    "n_embed = 8\n",
    "dt = 0.5\n",
    "N=10\n",
    "T=100000\n",
    "\n",
    "alpha = np.random.random(n_embed) # alpha\n",
    "exact = softmax(np.array(alpha))\n",
    "lam = max(alpha) # Initial value for lambda\n",
    "\n",
    "# Loops\n",
    "for _ in range(N): # Iterate to adjust lambda\n",
    "    spikes = [ExpBernoulliAlt(x,lam,T) for x in alpha] # Get spike trains for each channel\n",
    "    approx = [np.mean(z) for z in spikes]\n",
    "    total_probability = np.sum(approx)\n",
    "    print('Total probability (this should be 1): ', total_probability)\n",
    "    lam += dt*(total_probability-1) # How the fuck did copilot guess this line from \"lam += dt*\"?????!!!!!!!!!!\n",
    "error = np.sqrt(np.mean((exact-approx)**2)/np.mean(exact**2))*100\n",
    "\n",
    "print('\\n')\n",
    "print('Original vector: ',alpha)\n",
    "print('Exact softmax: ',exact)\n",
    "print('Approximation using spike: ',approx)\n",
    "print('Error: ',error,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention scores:  [[0.078 0.108 0.092 0.12  0.122]]\n",
      "Exact exponentials:  [[0.398 0.41  0.403 0.415 0.415]]\n",
      "Approximation using spikes:  [0.39  0.425 0.428 0.409 0.415]\n",
      "Error:  3.3229223179537892 %\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "n_embed=4 # Embedding dimension\n",
    "n_keys=5 # Number keys\n",
    "M=1000\n",
    "T=20000\n",
    "max_rate = 0.5\n",
    "lam=1.0\n",
    "\n",
    "# Get keys/query and compute exact scaled dot products\n",
    "q =  max_rate*np.random.random((n_embed,1)) # Query\n",
    "K = max_rate*np.random.random((n_embed,n_keys)) # Keys\n",
    "attn_scores = q.T@K/np.sqrt(n_embed) # Exact attention scores\n",
    "print(\"Attention scores: \",attn_scores)\n",
    "\n",
    "exact = np.exp(attn_scores-lam)\n",
    "print(\"Exact exponentials: \",exact)\n",
    "\n",
    "A_spikes = np.random.random((M,T,n_keys)) < lam/T\n",
    "B_spikes=approx_fn(q/lam,K,M*T,comb_method='OR').reshape(M,T,-1)\n",
    "attn_score_spikes = ~A_spikes | B_spikes # AND\n",
    "\n",
    "approx = np.mean(np.all(attn_score_spikes,axis=1),axis=0)\n",
    "error = np.sqrt(np.mean((approx-exact)**2)/np.mean(exact**2))\n",
    "print(\"Approximation using spikes: \",approx)\n",
    "print(\"Error: \",100*error,'%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## We can avoid doing the sum in the dot products...\n",
    "\n",
    "* Basic idea: $exp(q\\cdot k-\\lambda) = exp(\\sum_N q_is_i-\\lambda)=\\prod_N exp(r_is_i-\\lambda/N)$\n",
    "* This avoids summing spike trains, so it's okay if $r_is_i$ is close to 1 (i.e. we don't need sparsity).\n",
    "* We can do $N\\times K$ initial coin flips, each with probability $\\lambda/N$. \n",
    "* Whenever coin $(n,k)$ lands heads up, we perform a second coin flip with probability $r_ns_n/\\lambda\\sqrt{N}$.\n",
    "* If all of the second round coin flips come up heads, we transmit a spike.\n",
    "* Spike probability: $\\prod_n\\prod_k 1-\\frac{\\lambda}{K}(1-r_ns_n/\\lambda\\sqrt{N}) = \\prod_n [1-\\frac{\\lambda}{K}(1-r_ns_n/\\lambda\\sqrt{N})]^K\\prod_n [1-\\frac{\\lambda-r_ns_n/\\sqrt{N}}{K})]^K\\approx \\prod_n e^{r_ns_n/\\sqrt{N}-\\lambda}=e^{r\\cdot s/\\sqrt{N}-N\\lambda}$\n",
    "\n",
    "##### Below is a full exmaple, including adjusting $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total probability:  0.131\n",
      "Lambda:  1\n",
      "Total probability:  0.572\n",
      "Lambda:  0.6367000000000002\n",
      "Total probability:  0.9\n",
      "Lambda:  0.5198000000000002\n",
      "Total probability:  0.994\n",
      "Lambda:  0.4934000000000001\n",
      "Total probability:  1.027\n",
      "Lambda:  0.49170000000000014\n",
      "Total probability:  1.045\n",
      "Lambda:  0.49110000000000004\n",
      "Total probability:  0.923\n",
      "Lambda:  0.5037\n",
      "Total probability:  0.988\n",
      "Lambda:  0.49230000000000007\n",
      "Total probability:  1.04\n",
      "Lambda:  0.4903000000000001\n",
      "Total probability:  1.0150000000000001\n",
      "Lambda:  0.4934000000000001\n",
      "\n",
      "Attention scores:  [[0.414 0.294 0.567 0.362 0.166]]\n",
      "Exact softmax:  [[0.209 0.185 0.244 0.199 0.163]]\n",
      "Approximation using spikes:  [0.203 0.19  0.244 0.195 0.163]\n",
      "Error:  1.8828207345448267 %\n",
      "Total probability:  0.9951\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "n_embed=4 # Embedding dimension\n",
    "n_keys=5 # Number keys\n",
    "N=1000 # How many coins to flip in first phase\n",
    "T=200 \n",
    "dt=0.1\n",
    "lam=1\n",
    "max_rate = 1.0\n",
    "\n",
    "# Get keys/query and compute exact scaled dot products\n",
    "q =  max_rate*np.random.random((n_embed,1)) # Query\n",
    "K = max_rate*np.random.random((n_embed,n_keys)) # Keys\n",
    "\n",
    "# Get correct lambda value\n",
    "##################################################################################\n",
    "\n",
    "for i in range(50):\n",
    "    # Create spike arrays based on the values in q and K\n",
    "    q_spikes = np.random.random((N,T,n_embed,1))<q\n",
    "    K_spikes = np.random.random((N,T,n_embed,n_keys))<K\n",
    "    scaling_spikes = np.random.random((N,T,n_embed,n_keys)) < 1/(lam*np.sqrt(n_embed)) # K x N matrix of boolean mask\n",
    "    # scaling_spikes = np.random.random((1,T,n_embed,n_keys)) < 1/lam*np.sqrt(n_embed) # K x N matrix of boolean mask\n",
    "    A_spikes = np.random.random((N,T,n_embed,n_keys)) < lam/T\n",
    "    B_spikes = q_spikes & K_spikes & scaling_spikes\n",
    "    approx_spikes = ~A_spikes | B_spikes # A->B \n",
    "\n",
    "    approx = np.mean(np.all(approx_spikes,axis=(1,2)),axis=0)\n",
    "    if i%5==0:\n",
    "        print(\"Total probability: \",np.sum(approx))\n",
    "        print(\"Lambda: \",lam)\n",
    "    lam -= dt*(1-np.sum(approx)) # Adjust lambda\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "# Softmax\n",
    "####################################################################################\n",
    "N=10000\n",
    "T=1000\n",
    "\n",
    "attn_scores = q.T@K/np.sqrt(n_embed) # Exact attention scores\n",
    "print(\"\\nAttention scores: \",attn_scores)\n",
    "exact = softmax(attn_scores)\n",
    "print(\"Exact softmax: \",exact)\n",
    "\n",
    "# Create spike arrays based on the values in q and K\n",
    "q_spikes = np.random.random((N,T,n_embed,1))<q\n",
    "K_spikes = np.random.random((N,T,n_embed,n_keys))<K\n",
    "# scaling_spikes = np.random.random((N,T,n_embed,n_keys)) < 1/(lam*np.sqrt(n_embed)) # K x N matrix of boolean mask\n",
    "scaling_spikes = np.random.random((N,T,n_embed,n_keys)) < 1/(lam*np.sqrt(n_embed)) # K x N matrix of boolean mask\n",
    "A_spikes = np.random.random((N,T,n_embed,n_keys)) < lam/T\n",
    "B_spikes = q_spikes & K_spikes & scaling_spikes\n",
    "approx_spikes = ~A_spikes | B_spikes # A -> B\n",
    "\n",
    "approx = np.mean(np.all(approx_spikes,axis=(1,2)),axis=0)\n",
    "error = np.sqrt(np.mean((approx-exact)**2)/np.mean(exact**2))\n",
    "print(\"Approximation using spikes: \",approx)\n",
    "print(\"Error: \",100*error,'%')\n",
    "print(\"Total probability: \",np.sum(approx))\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
