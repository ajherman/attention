10.368858 M parameters
Found cached dataset parquet (file:///vast/home/ajherman/.cache/huggingface/datasets/nRuaif___parquet/nRuaif--tinystories-gpt4-69e0c67f20b31c3b/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)
Traceback (most recent call last):
  File "/vast/home/ajherman/attention/main.py", line 114, in <module>
    dataset = load_dataset("nRuaif/tinystories-gpt4",split="train")
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/vast/home/ajherman/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/load.py", line 1810, in load_dataset
    ds = builder_instance.as_dataset(split=split, verification_mode=verification_mode, in_memory=keep_in_memory)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/vast/home/ajherman/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/builder.py", line 1107, in as_dataset
    raise NotImplementedError(f"Loading a dataset cached in a {type(self._fs).__name__} is not supported.")
NotImplementedError: Loading a dataset cached in a LocalFileSystem is not supported.
10.368858 M parameters
Found cached dataset parquet (file:///vast/home/ajherman/.cache/huggingface/datasets/nRuaif___parquet/nRuaif--tinystories-gpt4-69e0c67f20b31c3b/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)
Traceback (most recent call last):
  File "/vast/home/ajherman/attention/main.py", line 114, in <module>
    dataset = load_dataset("nRuaif/tinystories-gpt4",split="train")
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/vast/home/ajherman/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/load.py", line 1810, in load_dataset
    ds = builder_instance.as_dataset(split=split, verification_mode=verification_mode, in_memory=keep_in_memory)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/vast/home/ajherman/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/builder.py", line 1107, in as_dataset
    raise NotImplementedError(f"Loading a dataset cached in a {type(self._fs).__name__} is not supported.")
NotImplementedError: Loading a dataset cached in a LocalFileSystem is not supported.
10.368858 M parameters
Traceback (most recent call last):
  File "/vast/home/ajherman/attention/main.py", line 115, in <module>
    dataset = load_dataset("nRuaif/tinystories-gpt4",cache_dir=data_cache_dir,split='train')
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/vast/home/ajherman/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/load.py", line 1773, in load_dataset
    builder_instance = load_dataset_builder(
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/vast/home/ajherman/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/load.py", line 1528, in load_dataset_builder
    builder_instance: DatasetBuilder = builder_cls(
                                       ^^^^^^^^^^^^
  File "/vast/home/ajherman/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/builder.py", line 378, in __init__
    os.makedirs(self._cache_dir_root, exist_ok=True)
  File "<frozen os>", line 215, in makedirs
  File "<frozen os>", line 225, in makedirs
PermissionError: [Errno 13] Permission denied: '/home/ari'
10.368858 M parameters
Traceback (most recent call last):
  File "/vast/home/ajherman/attention/main.py", line 115, in <module>
    dataset = load_dataset("nRuaif/tinystories-gpt4",cache_dir=data_cache_dir,split='train')
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/vast/home/ajherman/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/load.py", line 1773, in load_dataset
    builder_instance = load_dataset_builder(
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/vast/home/ajherman/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/load.py", line 1528, in load_dataset_builder
    builder_instance: DatasetBuilder = builder_cls(
                                       ^^^^^^^^^^^^
  File "/vast/home/ajherman/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/builder.py", line 378, in __init__
    os.makedirs(self._cache_dir_root, exist_ok=True)
  File "<frozen os>", line 225, in makedirs
PermissionError: [Errno 13] Permission denied: '/ram/mnt/local/ssd1'
10.368858 M parameters
Downloading and preparing dataset parquet/nRuaif--tinystories-gpt4 to file:///ram/tmp/nRuaif___parquet/nRuaif--tinystories-gpt4-69e0c67f20b31c3b/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...
Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]
Downloading data:   0%|          | 0.00/1.13G [00:00<?, ?B/s][A
Downloading data:   0%|          | 460k/1.13G [00:00<04:06, 4.57MB/s][A
Downloading data:   1%|          | 5.89M/1.13G [00:00<00:33, 33.7MB/s][A
Downloading data:   1%|▏         | 16.6M/1.13G [00:00<00:16, 65.5MB/s][A
Downloading data:   2%|▏         | 26.1M/1.13G [00:00<00:14, 76.7MB/s][A
Downloading data:   3%|▎         | 37.1M/1.13G [00:00<00:12, 88.8MB/s][A
Downloading data:   4%|▍         | 49.0M/1.13G [00:00<00:10, 98.8MB/s][A
Downloading data:   5%|▌         | 60.3M/1.13G [00:00<00:10, 104MB/s] [A
Downloading data:   6%|▋         | 72.0M/1.13G [00:00<00:09, 108MB/s][A
Downloading data:   7%|▋         | 82.8M/1.13G [00:00<00:09, 107MB/s][A
Downloading data:   9%|▊         | 96.0M/1.13G [00:01<00:08, 115MB/s][A
Downloading data:  10%|▉         | 108M/1.13G [00:01<00:08, 115MB/s] [A
Downloading data:  11%|█         | 119M/1.13G [00:01<00:08, 116MB/s][A
Downloading data:  12%|█▏        | 131M/1.13G [00:01<00:09, 108MB/s][A
Downloading data:  13%|█▎        | 144M/1.13G [00:01<00:08, 115MB/s][A
Downloading data:  14%|█▍        | 156M/1.13G [00:01<00:08, 112MB/s][A
Downloading data:  15%|█▌        | 169M/1.13G [00:01<00:08, 117MB/s][A
Downloading data:  16%|█▌        | 181M/1.13G [00:01<00:08, 114MB/s][A
Downloading data:  17%|█▋        | 194M/1.13G [00:01<00:07, 118MB/s][A
Downloading data:  18%|█▊        | 206M/1.13G [00:01<00:07, 117MB/s][A
Downloading data:  19%|█▉        | 217M/1.13G [00:02<00:07, 117MB/s][A
Downloading data:  20%|██        | 229M/1.13G [00:02<00:07, 118MB/s][A
Downloading data:  21%|██▏       | 241M/1.13G [00:02<00:07, 118MB/s][A
Downloading data:  22%|██▏       | 253M/1.13G [00:02<00:07, 118MB/s][A
Downloading data:  24%|██▎       | 265M/1.13G [00:02<00:07, 118MB/s][A
Downloading data:  25%|██▍       | 276M/1.13G [00:02<00:07, 117MB/s][A
Downloading data:  26%|██▌       | 288M/1.13G [00:02<00:07, 117MB/s][A
Downloading data:  27%|██▋       | 300M/1.13G [00:02<00:07, 112MB/s][A
Downloading data:  28%|██▊       | 311M/1.13G [00:02<00:07, 112MB/s][A
Downloading data:  29%|██▉       | 325M/1.13G [00:02<00:06, 119MB/s][A
Downloading data:  30%|██▉       | 337M/1.13G [00:03<00:06, 118MB/s][A
Downloading data:  31%|███       | 349M/1.13G [00:03<00:06, 118MB/s][A
Downloading data:  32%|███▏      | 360M/1.13G [00:03<00:06, 118MB/s][A
Downloading data:  33%|███▎      | 372M/1.13G [00:03<00:06, 118MB/s][A
Downloading data:  34%|███▍      | 384M/1.13G [00:03<00:06, 118MB/s][A
Downloading data:  35%|███▌      | 396M/1.13G [00:03<00:06, 117MB/s][A
Downloading data:  36%|███▌      | 408M/1.13G [00:03<00:06, 116MB/s][A
Downloading data:  37%|███▋      | 420M/1.13G [00:03<00:06, 117MB/s][A
Downloading data:  38%|███▊      | 431M/1.13G [00:03<00:05, 117MB/s][A
Downloading data:  39%|███▉      | 443M/1.13G [00:03<00:05, 118MB/s][A
Downloading data:  40%|████      | 455M/1.13G [00:04<00:05, 117MB/s][A
Downloading data:  41%|████▏     | 467M/1.13G [00:04<00:05, 117MB/s][A
Downloading data:  42%|████▏     | 478M/1.13G [00:04<00:05, 117MB/s][A
Downloading data:  44%|████▎     | 490M/1.13G [00:04<00:05, 117MB/s][A
Downloading data:  45%|████▍     | 502M/1.13G [00:04<00:05, 117MB/s][A
Downloading data:  46%|████▌     | 514M/1.13G [00:04<00:05, 117MB/s][A
Downloading data:  47%|████▋     | 526M/1.13G [00:04<00:05, 114MB/s][A
Downloading data:  48%|████▊     | 538M/1.13G [00:04<00:04, 118MB/s][A
Downloading data:  49%|████▉     | 550M/1.13G [00:04<00:04, 118MB/s][A
Downloading data:  50%|████▉     | 562M/1.13G [00:05<00:04, 117MB/s][A
Downloading data:  51%|█████     | 574M/1.13G [00:05<00:04, 113MB/s][A
Downloading data:  52%|█████▏    | 585M/1.13G [00:05<00:04, 109MB/s][A
Downloading data:  53%|█████▎    | 597M/1.13G [00:05<00:04, 112MB/s][A
Downloading data:  54%|█████▍    | 611M/1.13G [00:05<00:04, 119MB/s][A
Downloading data:  55%|█████▌    | 623M/1.13G [00:05<00:04, 102MB/s][A
Downloading data:  56%|█████▋    | 635M/1.13G [00:05<00:04, 109MB/s][A
Downloading data:  58%|█████▊    | 648M/1.13G [00:05<00:04, 114MB/s][A
Downloading data:  59%|█████▊    | 660M/1.13G [00:05<00:04, 115MB/s][A
Downloading data:  60%|█████▉    | 672M/1.13G [00:06<00:04, 111MB/s][A
Downloading data:  61%|██████    | 684M/1.13G [00:06<00:03, 115MB/s][A
Downloading data:  62%|██████▏   | 696M/1.13G [00:06<00:03, 114MB/s][A
Downloading data:  63%|██████▎   | 709M/1.13G [00:06<00:03, 118MB/s][A
Downloading data:  64%|██████▍   | 721M/1.13G [00:06<00:03, 112MB/s][A
Downloading data:  65%|██████▌   | 734M/1.13G [00:06<00:03, 118MB/s][A
Downloading data:  66%|██████▋   | 746M/1.13G [00:06<00:03, 119MB/s][A
Downloading data:  67%|██████▋   | 758M/1.13G [00:06<00:03, 114MB/s][A
Downloading data:  68%|██████▊   | 771M/1.13G [00:06<00:03, 117MB/s][A
Downloading data:  69%|██████▉   | 782M/1.13G [00:06<00:03, 110MB/s][A
Downloading data:  70%|███████   | 794M/1.13G [00:07<00:03, 111MB/s][A
Downloading data:  72%|███████▏  | 806M/1.13G [00:07<00:02, 114MB/s][A
Downloading data:  73%|███████▎  | 819M/1.13G [00:07<00:02, 118MB/s][A
Downloading data:  74%|███████▍  | 831M/1.13G [00:07<00:02, 115MB/s][A
Downloading data:  75%|███████▍  | 844M/1.13G [00:07<00:02, 119MB/s][A
Downloading data:  76%|███████▌  | 855M/1.13G [00:07<00:02, 115MB/s][A
Downloading data:  77%|███████▋  | 868M/1.13G [00:07<00:02, 119MB/s][A
Downloading data:  78%|███████▊  | 880M/1.13G [00:07<00:02, 118MB/s][A
Downloading data:  79%|███████▉  | 892M/1.13G [00:07<00:02, 116MB/s][A
Downloading data:  80%|████████  | 903M/1.13G [00:08<00:01, 114MB/s][A
Downloading data:  81%|████████▏ | 916M/1.13G [00:08<00:01, 117MB/s][A
Downloading data:  82%|████████▏ | 928M/1.13G [00:08<00:01, 118MB/s][A
Downloading data:  83%|████████▎ | 940M/1.13G [00:08<00:01, 114MB/s][A
Downloading data:  85%|████████▍ | 952M/1.13G [00:08<00:01, 102MB/s][A
Downloading data:  86%|████████▌ | 966M/1.13G [00:08<00:01, 113MB/s][A
Downloading data:  87%|████████▋ | 978M/1.13G [00:08<00:01, 115MB/s][A
Downloading data:  88%|████████▊ | 989M/1.13G [00:08<00:01, 110MB/s][A
Downloading data:  89%|████████▉ | 1.00G/1.13G [00:08<00:01, 116MB/s][A
Downloading data:  90%|█████████ | 1.01G/1.13G [00:08<00:00, 116MB/s][A
Downloading data:  91%|█████████ | 1.03G/1.13G [00:09<00:00, 116MB/s][A
Downloading data:  92%|█████████▏| 1.04G/1.13G [00:09<00:00, 108MB/s][A
Downloading data:  93%|█████████▎| 1.05G/1.13G [00:09<00:00, 115MB/s][A
Downloading data:  94%|█████████▍| 1.06G/1.13G [00:09<00:00, 111MB/s][A
Downloading data:  96%|█████████▌| 1.08G/1.13G [00:09<00:00, 117MB/s][A
Downloading data:  97%|█████████▋| 1.09G/1.13G [00:09<00:00, 113MB/s][A
Downloading data:  98%|█████████▊| 1.10G/1.13G [00:09<00:00, 114MB/s][A
Downloading data:  99%|█████████▊| 1.11G/1.13G [00:09<00:00, 116MB/s][A
Downloading data: 100%|█████████▉| 1.12G/1.13G [00:09<00:00, 120MB/s][ADownloading data: 100%|██████████| 1.13G/1.13G [00:09<00:00, 113MB/s]
Downloading data files:  50%|█████     | 1/2 [00:10<00:10, 10.93s/it]
Downloading data:   0%|          | 0.00/11.4M [00:00<?, ?B/s][A
Downloading data:   5%|▌         | 612k/11.4M [00:00<00:01, 6.00MB/s][A
Downloading data:  57%|█████▋    | 6.47M/11.4M [00:00<00:00, 36.5MB/s][ADownloading data: 100%|██████████| 11.4M/11.4M [00:00<00:00, 41.3MB/s]
Downloading data files: 100%|██████████| 2/2 [00:12<00:00,  5.24s/it]Downloading data files: 100%|██████████| 2/2 [00:12<00:00,  6.09s/it]
Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]Extracting data files: 100%|██████████| 2/2 [00:00<00:00, 1699.47it/s]
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 10000 examples [00:00, 20005.69 examples/s]Generating train split: 80000 examples [00:00, 165407.80 examples/s]Generating train split: 160000 examples [00:00, 294429.65 examples/s]Generating train split: 240000 examples [00:00, 390890.90 examples/s]Generating train split: 310000 examples [00:00, 454220.38 examples/s]Generating train split: 380000 examples [00:01, 501546.90 examples/s]Generating train split: 460000 examples [00:01, 536344.59 examples/s]Generating train split: 540000 examples [00:01, 565670.60 examples/s]Generating train split: 620000 examples [00:01, 589160.95 examples/s]Generating train split: 690000 examples [00:01, 600104.04 examples/s]Generating train split: 760000 examples [00:01, 605122.19 examples/s]Generating train split: 840000 examples [00:01, 610972.89 examples/s]Generating train split: 920000 examples [00:01, 618349.46 examples/s]Generating train split: 1000000 examples [00:02, 619944.84 examples/s]Generating train split: 1080000 examples [00:02, 625437.42 examples/s]Generating train split: 1150000 examples [00:02, 625382.85 examples/s]Generating train split: 1230000 examples [00:02, 629709.35 examples/s]Generating train split: 1310000 examples [00:02, 629905.37 examples/s]Generating train split: 1390000 examples [00:02, 642975.74 examples/s]Generating train split: 1470000 examples [00:02, 640875.21 examples/s]Generating train split: 1550000 examples [00:02, 643958.04 examples/s]Generating train split: 1620000 examples [00:03, 632179.50 examples/s]Generating train split: 1700000 examples [00:03, 636711.90 examples/s]Generating train split: 1780000 examples [00:03, 638680.36 examples/s]Generating train split: 1860000 examples [00:03, 640299.74 examples/s]Generating train split: 1930000 examples [00:03, 636743.29 examples/s]Generating train split: 2010000 examples [00:03, 641177.97 examples/s]Generating train split: 2080000 examples [00:03, 636803.42 examples/s]Generating train sDataset parquet downloaded and prepared to file:///ram/tmp/nRuaif___parquet/nRuaif--tinystories-gpt4-69e0c67f20b31c3b/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.
plit: 2160000 examples [00:03, 645673.48 examples/s]Generating train split: 2240000 examples [00:04, 650960.77 examples/s]Generating train split: 2320000 examples [00:04, 650100.18 examples/s]Generating train split: 2400000 examples [00:04, 646247.11 examples/s]Generating train split: 2470000 examples [00:04, 637484.16 examples/s]Generating train split: 2550000 examples [00:04, 643731.09 examples/s]Generating train split: 2630000 examples [00:04, 644069.74 examples/s]Generating train split: 2700000 examples [00:04, 635403.59 examples/s]                                                                      Generating test split: 0 examples [00:00, ? examples/s]                                                       Traceback (most recent call last):
  File "/vast/home/ajherman/attention/main.py", line 115, in <module>
    dataset = load_dataset("nRuaif/tinystories-gpt4",cache_dir=data_cache_dir,split='train')
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/vast/home/ajherman/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/load.py", line 1810, in load_dataset
    ds = builder_instance.as_dataset(split=split, verification_mode=verification_mode, in_memory=keep_in_memory)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/vast/home/ajherman/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/builder.py", line 1107, in as_dataset
    raise NotImplementedError(f"Loading a dataset cached in a {type(self._fs).__name__} is not supported.")
NotImplementedError: Loading a dataset cached in a LocalFileSystem is not supported.
