10.389262 M parameters
Found cached dataset parquet (file:///vast/home/ajherman/.cache/huggingface/datasets/nRuaif___parquet/nRuaif--tinystories-gpt4-69e0c67f20b31c3b/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)
Traceback (most recent call last):
  File "/vast/home/ajherman/attention/main.py", line 114, in <module>
    dataset = load_dataset("nRuaif/tinystories-gpt4",split="train")
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/vast/home/ajherman/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/load.py", line 1810, in load_dataset
    ds = builder_instance.as_dataset(split=split, verification_mode=verification_mode, in_memory=keep_in_memory)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/vast/home/ajherman/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/builder.py", line 1107, in as_dataset
    raise NotImplementedError(f"Loading a dataset cached in a {type(self._fs).__name__} is not supported.")
NotImplementedError: Loading a dataset cached in a LocalFileSystem is not supported.
10.389262 M parameters
Found cached dataset parquet (file:///vast/home/ajherman/.cache/huggingface/datasets/nRuaif___parquet/nRuaif--tinystories-gpt4-69e0c67f20b31c3b/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)
Traceback (most recent call last):
  File "/vast/home/ajherman/attention/main.py", line 114, in <module>
    dataset = load_dataset("nRuaif/tinystories-gpt4",split="train")
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/vast/home/ajherman/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/load.py", line 1810, in load_dataset
    ds = builder_instance.as_dataset(split=split, verification_mode=verification_mode, in_memory=keep_in_memory)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/vast/home/ajherman/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/builder.py", line 1107, in as_dataset
    raise NotImplementedError(f"Loading a dataset cached in a {type(self._fs).__name__} is not supported.")
NotImplementedError: Loading a dataset cached in a LocalFileSystem is not supported.
10.389262 M parameters
Traceback (most recent call last):
  File "/vast/home/ajherman/attention/main.py", line 115, in <module>
    dataset = load_dataset("nRuaif/tinystories-gpt4",cache_dir=data_cache_dir,split='train')
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/vast/home/ajherman/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/load.py", line 1773, in load_dataset
    builder_instance = load_dataset_builder(
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/vast/home/ajherman/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/load.py", line 1528, in load_dataset_builder
    builder_instance: DatasetBuilder = builder_cls(
                                       ^^^^^^^^^^^^
  File "/vast/home/ajherman/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/builder.py", line 378, in __init__
    os.makedirs(self._cache_dir_root, exist_ok=True)
  File "<frozen os>", line 215, in makedirs
  File "<frozen os>", line 225, in makedirs
PermissionError: [Errno 13] Permission denied: '/home/ari'
10.389262 M parameters
Traceback (most recent call last):
  File "/vast/home/ajherman/attention/main.py", line 115, in <module>
    dataset = load_dataset("nRuaif/tinystories-gpt4",cache_dir=data_cache_dir,split='train')
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/vast/home/ajherman/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/load.py", line 1773, in load_dataset
    builder_instance = load_dataset_builder(
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/vast/home/ajherman/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/load.py", line 1528, in load_dataset_builder
    builder_instance: DatasetBuilder = builder_cls(
                                       ^^^^^^^^^^^^
  File "/vast/home/ajherman/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/builder.py", line 378, in __init__
    os.makedirs(self._cache_dir_root, exist_ok=True)
  File "<frozen os>", line 225, in makedirs
PermissionError: [Errno 13] Permission denied: '/ram/mnt/local/ssd1'
10.389262 M parameters
Downloading and preparing dataset parquet/nRuaif--tinystories-gpt4 to file:///ram/tmp/nRuaif___parquet/nRuaif--tinystories-gpt4-69e0c67f20b31c3b/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...
Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]
Downloading data:   0%|          | 0.00/1.13G [00:00<?, ?B/s][A
Downloading data:   0%|          | 457k/1.13G [00:00<04:06, 4.56MB/s][A
Downloading data:   0%|          | 5.15M/1.13G [00:00<00:38, 29.5MB/s][A
Downloading data:   1%|▏         | 15.0M/1.13G [00:00<00:18, 61.1MB/s][A
Downloading data:   2%|▏         | 27.9M/1.13G [00:00<00:12, 87.7MB/s][A
Downloading data:   3%|▎         | 39.3M/1.13G [00:00<00:11, 97.3MB/s][A
Downloading data:   4%|▍         | 49.0M/1.13G [00:00<00:11, 95.5MB/s][A
Downloading data:   5%|▌         | 61.0M/1.13G [00:00<00:10, 103MB/s] [A
Downloading data:   7%|▋         | 74.1M/1.13G [00:00<00:09, 112MB/s][A
Downloading data:   8%|▊         | 85.3M/1.13G [00:00<00:09, 112MB/s][A
Downloading data:   9%|▊         | 96.6M/1.13G [00:01<00:09, 112MB/s][A
Downloading data:  10%|▉         | 108M/1.13G [00:01<00:09, 111MB/s] [A
Downloading data:  11%|█         | 119M/1.13G [00:01<00:09, 110MB/s][A
Downloading data:  12%|█▏        | 130M/1.13G [00:01<00:08, 111MB/s][A
Downloading data:  13%|█▎        | 142M/1.13G [00:01<00:08, 112MB/s][A
Downloading data:  14%|█▎        | 153M/1.13G [00:01<00:08, 112MB/s][A
Downloading data:  15%|█▍        | 165M/1.13G [00:01<00:08, 114MB/s][A
Downloading data:  16%|█▌        | 176M/1.13G [00:01<00:08, 113MB/s][A
Downloading data:  17%|█▋        | 188M/1.13G [00:01<00:08, 115MB/s][A
Downloading data:  18%|█▊        | 199M/1.13G [00:01<00:08, 114MB/s][A
Downloading data:  19%|█▉        | 211M/1.13G [00:02<00:07, 115MB/s][A
Downloading data:  20%|█▉        | 223M/1.13G [00:02<00:07, 114MB/s][A
Downloading data:  21%|██        | 234M/1.13G [00:02<00:07, 112MB/s][A
Downloading data:  22%|██▏       | 245M/1.13G [00:02<00:07, 110MB/s][A
Downloading data:  23%|██▎       | 257M/1.13G [00:02<00:07, 113MB/s][A
Downloading data:  24%|██▍       | 269M/1.13G [00:02<00:07, 115MB/s][A
Downloading data:  25%|██▍       | 281M/1.13G [00:02<00:07, 115MB/s][A
Downloading data:  26%|██▌       | 292M/1.13G [00:02<00:07, 115MB/s][A
Downloading data:  27%|██▋       | 304M/1.13G [00:02<00:07, 116MB/s][A
Downloading data:  28%|██▊       | 316M/1.13G [00:02<00:06, 116MB/s][A
Downloading data:  29%|██▉       | 327M/1.13G [00:03<00:06, 116MB/s][A
Downloading data:  30%|███       | 339M/1.13G [00:03<00:06, 117MB/s][A
Downloading data:  31%|███       | 351M/1.13G [00:03<00:06, 116MB/s][A
Downloading data:  32%|███▏      | 362M/1.13G [00:03<00:06, 115MB/s][A
Downloading data:  33%|███▎      | 374M/1.13G [00:03<00:06, 116MB/s][A
Downloading data:  34%|███▍      | 386M/1.13G [00:03<00:06, 116MB/s][A
Downloading data:  35%|███▌      | 397M/1.13G [00:03<00:06, 116MB/s][A
Downloading data:  36%|███▋      | 409M/1.13G [00:03<00:06, 116MB/s][A
Downloading data:  37%|███▋      | 420M/1.13G [00:03<00:06, 114MB/s][A
Downloading data:  38%|███▊      | 432M/1.13G [00:03<00:06, 115MB/s][A
Downloading data:  39%|███▉      | 444M/1.13G [00:04<00:05, 115MB/s][A
Downloading data:  40%|████      | 455M/1.13G [00:04<00:05, 115MB/s][A
Downloading data:  41%|████▏     | 467M/1.13G [00:04<00:05, 113MB/s][A
Downloading data:  43%|████▎     | 479M/1.13G [00:04<00:05, 114MB/s][A
Downloading data:  44%|████▎     | 490M/1.13G [00:04<00:05, 115MB/s][A
Downloading data:  45%|████▍     | 502M/1.13G [00:04<00:05, 113MB/s][A
Downloading data:  46%|████▌     | 513M/1.13G [00:04<00:05, 112MB/s][A
Downloading data:  47%|████▋     | 525M/1.13G [00:04<00:05, 115MB/s][A
Downloading data:  48%|████▊     | 537M/1.13G [00:04<00:05, 111MB/s][A
Downloading data:  49%|████▉     | 549M/1.13G [00:04<00:05, 114MB/s][A
Downloading data:  50%|████▉     | 561M/1.13G [00:05<00:05, 111MB/s][A
Downloading data:  51%|█████     | 572M/1.13G [00:05<00:05, 111MB/s][A
Downloading data:  52%|█████▏    | 583M/1.13G [00:05<00:04, 111MB/s][A
Downloading data:  53%|█████▎    | 594M/1.13G [00:05<00:04, 111MB/s][A
Downloading data:  54%|█████▍    | 606M/1.13G [00:05<00:04, 113MB/s][A
Downloading data:  55%|█████▍    | 618M/1.13G [00:05<00:04, 112MB/s][A
Downloading data:  56%|█████▌    | 629M/1.13G [00:05<00:04, 110MB/s][A
Downloading data:  57%|█████▋    | 640M/1.13G [00:05<00:04, 111MB/s][A
Downloading data:  58%|█████▊    | 652M/1.13G [00:05<00:04, 111MB/s][A
Downloading data:  59%|█████▉    | 663M/1.13G [00:06<00:04, 111MB/s][A
Downloading data:  60%|█████▉    | 674M/1.13G [00:06<00:04, 111MB/s][A
Downloading data:  61%|██████    | 685M/1.13G [00:06<00:03, 110MB/s][A
Downloading data:  62%|██████▏   | 696M/1.13G [00:06<00:03, 111MB/s][A
Downloading data:  63%|██████▎   | 708M/1.13G [00:06<00:03, 112MB/s][A
Downloading data:  64%|██████▍   | 719M/1.13G [00:06<00:03, 111MB/s][A
Downloading data:  65%|██████▍   | 730M/1.13G [00:06<00:03, 110MB/s][A
Downloading data:  66%|██████▌   | 741M/1.13G [00:06<00:03, 110MB/s][A
Downloading data:  67%|██████▋   | 753M/1.13G [00:06<00:03, 111MB/s][A
Downloading data:  68%|██████▊   | 764M/1.13G [00:06<00:03, 111MB/s][A
Downloading data:  69%|██████▉   | 775M/1.13G [00:07<00:03, 112MB/s][A
Downloading data:  70%|██████▉   | 787M/1.13G [00:07<00:03, 111MB/s][A
Downloading data:  71%|███████   | 798M/1.13G [00:07<00:02, 112MB/s][A
Downloading data:  72%|███████▏  | 810M/1.13G [00:07<00:02, 115MB/s][A
Downloading data:  73%|███████▎  | 822M/1.13G [00:07<00:02, 112MB/s][A
Downloading data:  74%|███████▍  | 833M/1.13G [00:07<00:02, 103MB/s][A
Downloading data:  75%|███████▌  | 846M/1.13G [00:07<00:02, 109MB/s][A
Downloading data:  76%|███████▌  | 858M/1.13G [00:07<00:02, 114MB/s][A
Downloading data:  77%|███████▋  | 870M/1.13G [00:07<00:02, 111MB/s][A
Downloading data:  78%|███████▊  | 881M/1.13G [00:07<00:02, 111MB/s][A
Downloading data:  79%|███████▉  | 892M/1.13G [00:08<00:02, 111MB/s][A
Downloading data:  80%|████████  | 904M/1.13G [00:08<00:01, 112MB/s][A
Downloading data:  81%|████████▏ | 915M/1.13G [00:08<00:01, 106MB/s][A
Downloading data:  82%|████████▏ | 928M/1.13G [00:08<00:01, 113MB/s][A
Downloading data:  83%|████████▎ | 940M/1.13G [00:08<00:01, 114MB/s][A
Downloading data:  85%|████████▍ | 951M/1.13G [00:08<00:01, 115MB/s][A
Downloading data:  86%|████████▌ | 963M/1.13G [00:08<00:01, 109MB/s][A
Downloading data:  87%|████████▋ | 974M/1.13G [00:08<00:01, 109MB/s][A
Downloading data:  87%|████████▋ | 985M/1.13G [00:08<00:01, 109MB/s][A
Downloading data:  88%|████████▊ | 996M/1.13G [00:09<00:01, 108MB/s][A
Downloading data:  90%|████████▉ | 1.01G/1.13G [00:09<00:01, 112MB/s][A
Downloading data:  91%|█████████ | 1.02G/1.13G [00:09<00:01, 103MB/s][A
Downloading data:  91%|█████████▏| 1.03G/1.13G [00:09<00:00, 101MB/s][A
Downloading data:  93%|█████████▎| 1.04G/1.13G [00:09<00:00, 109MB/s][A
Downloading data:  94%|█████████▎| 1.06G/1.13G [00:09<00:00, 112MB/s][A
Downloading data:  95%|█████████▍| 1.07G/1.13G [00:09<00:00, 113MB/s][A
Downloading data:  96%|█████████▌| 1.08G/1.13G [00:09<00:00, 114MB/s][A
Downloading data:  97%|█████████▋| 1.09G/1.13G [00:09<00:00, 115MB/s][A
Downloading data:  98%|█████████▊| 1.10G/1.13G [00:09<00:00, 116MB/s][A
Downloading data:  99%|█████████▉| 1.11G/1.13G [00:10<00:00, 116MB/s][A
Downloading data: 100%|█████████▉| 1.13G/1.13G [00:10<00:00, 68.3MB/s][ADownloading data: 100%|██████████| 1.13G/1.13G [00:10<00:00, 108MB/s] 
Downloading data files:  50%|█████     | 1/2 [00:11<00:11, 11.29s/it]
Downloading data:   0%|          | 0.00/11.4M [00:00<?, ?B/s][A
Downloading data:   4%|▍         | 475k/11.4M [00:00<00:02, 4.75MB/s][A
Downloading data:  51%|█████     | 5.75M/11.4M [00:00<00:00, 33.0MB/s][ADownloading data: 100%|██████████| 11.4M/11.4M [00:00<00:00, 46.3MB/s]
Downloading data files: 100%|██████████| 2/2 [00:12<00:00,  5.25s/it]Downloading data files: 100%|██████████| 2/2 [00:12<00:00,  6.15s/it]
Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]Extracting data files: 100%|██████████| 2/2 [00:00<00:00, 1698.10it/s]
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 10000 examples [00:00, 20860.37 examples/s]Generating train split: 80000 examples [00:00, 169838.46 examples/s]Generating train split: 160000 examples [00:00, 298082.86 examples/s]Generating train split: 240000 examples [00:00, 390675.92 examples/s]Generating train split: 310000 examples [00:00, 450863.12 examples/s]Generating train split: 380000 examples [00:01, 493998.15 examples/s]Generating train split: 460000 examples [00:01, 531425.29 examples/s]Generating train split: 540000 examples [00:01, 558520.32 examples/s]Generating train split: 620000 examples [00:01, 582264.35 examples/s]Generating train split: 690000 examples [00:01, 594974.99 examples/s]Generating train split: 760000 examples [00:01, 601309.75 examples/s]Generating train split: 840000 examples [00:01, 608171.33 examples/s]Generating train split: 920000 examples [00:01, 615103.50 examples/s]Generating train split: 1000000 examples [00:02, 617915.34 examples/s]Generating train split: 1080000 examples [00:02, 624909.92 examples/s]Generating train split: 1150000 examples [00:02, 625974.79 examples/s]Generating train split: 1230000 examples [00:02, 632473.62 examples/s]Generating train split: 1310000 examples [00:02, 635766.78 examples/s]Generating train split: 1390000 examples [00:02, 647363.00 examples/s]Generating train split: 1460000 examples [00:02, 645602.87 examples/s]Generating train split: 1530000 examples [00:02, 636415.82 examples/s]Generating train split: 1610000 examples [00:03, 629912.62 examples/s]Generating train split: 1690000 examples [00:03, 626901.71 examples/s]Generating train split: 1760000 examples [00:03, 625118.96 examples/s]Generating train split: 1830000 examples [00:03, 621226.66 examples/s]Generating train split: 1910000 examples [00:03, 617196.70 examples/s]Generating train split: 1990000 examples [00:03, 615885.19 examples/s]Generating train split: 2070000 examples [00:03, 619950.70 examples/s]Generating train sDataset parquet downloaded and prepared to file:///ram/tmp/nRuaif___parquet/nRuaif--tinystories-gpt4-69e0c67f20b31c3b/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.
plit: 2140000 examples [00:03, 616621.33 examples/s]Generating train split: 2220000 examples [00:04, 628992.79 examples/s]Generating train split: 2290000 examples [00:04, 625514.15 examples/s]Generating train split: 2360000 examples [00:04, 624609.86 examples/s]Generating train split: 2430000 examples [00:04, 622416.56 examples/s]Generating train split: 2510000 examples [00:04, 632558.51 examples/s]Generating train split: 2590000 examples [00:04, 633991.82 examples/s]Generating train split: 2670000 examples [00:04, 633511.56 examples/s]                                                                      Generating test split: 0 examples [00:00, ? examples/s]                                                       Traceback (most recent call last):
  File "/vast/home/ajherman/attention/main.py", line 115, in <module>
    dataset = load_dataset("nRuaif/tinystories-gpt4",cache_dir=data_cache_dir,split='train')
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/vast/home/ajherman/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/load.py", line 1810, in load_dataset
    ds = builder_instance.as_dataset(split=split, verification_mode=verification_mode, in_memory=keep_in_memory)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/vast/home/ajherman/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/builder.py", line 1107, in as_dataset
    raise NotImplementedError(f"Loading a dataset cached in a {type(self._fs).__name__} is not supported.")
NotImplementedError: Loading a dataset cached in a LocalFileSystem is not supported.
